{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenAI.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Installing OpenAI library\n",
        "\n",
        "Principles will be very similar to other AI libraries (Mistral, etc)"
      ],
      "metadata": {
        "id": "cPPDxkbtuoRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZnYIGn7bsV8",
        "outputId": "aedd8bbf-9326-4ac3-f812-ebc14a6c2ddb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.6.1-py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: typing-extensions, h11, httpcore, httpx, openai\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.6.1 typing-extensions-4.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "snFB8EfCbE8y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass # standard library\n",
        "secret = getpass('Enter the secret API key for OpenAI value: ')"
      ],
      "metadata": {
        "id": "Zf5SaV5Wu7JT",
        "outputId": "f95592bc-f701-4226-dc43-6d9f870a370b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the secret API key for OpenAI value: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# openai.api_key = \"use_your_own_key!\"  #never share your private API keys with the world! read them from enviroment or private text file\n",
        "# or using getpass and copy pasting (like I did - not very convenient but good for one time use)\n",
        "# alternatives, store API keys on your Google Drive - personally I do not recommend\n",
        "# there is also something called Google Secrets, again I personally do not trust it, but your mileage may vary\n",
        "openai.api_key = secret  #never share your private API keys with the world! read them from enviroment or private text file"
      ],
      "metadata": {
        "id": "DVAjoD-bb4Vf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accessing the API\n",
        "\n",
        "https://github.com/openai/openai-python - documents the changes\n",
        "\n",
        "Since this is cutting edge research, API changes quite often.\n",
        "\n",
        "Expect things to stabilize in a few years."
      ],
      "metadata": {
        "id": "NUcrvN9ivPWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    # api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
        "    api_key=secret,\n",
        ")"
      ],
      "metadata": {
        "id": "aFmfUYbFvmWb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Say this is a test but translate into Latvian\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"gpt-3.5-turbo\", # this is among the cheapest of the models similar to the free version on ChatGPT\n",
        ")"
      ],
      "metadata": {
        "id": "HkelQakVvedo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_completion.json"
      ],
      "metadata": {
        "id": "CP9VHpHevzmc",
        "outputId": "160eeeb9-4c92-4ad1-bb43-6f93ea150144",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method BaseModel.json of ChatCompletion(id='chatcmpl-8Ya3kHXNIntrksH41hyZ7FRyXcMJs', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Saki, ka ≈°is ir tests.', role='assistant', function_call=None, tool_calls=None))], created=1703252456, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=9, prompt_tokens=18, total_tokens=27))>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "1L3M1pPewD5Q",
        "outputId": "d66176dc-082d-4357-d63d-e6013f62ea37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Saki, ka ≈°is ir tests.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(chat_completion.choices) # how many choices do we have?"
      ],
      "metadata": {
        "id": "am4dU3p9wvqr",
        "outputId": "02c929db-3a00-4cd7-8ced-314b987da665",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Old API call - for historic purposes - changed in November 2023"
      ],
      "metadata": {
        "id": "OISUWA1AxD7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci\",\n",
        "  prompt=\"Social media post: \\\"That new Spider Man movie stinks to high heaven\\\"\\nSentiment (positive, neutral, negative):\",\n",
        "  temperature=0,\n",
        "  max_tokens=1,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")"
      ],
      "metadata": {
        "id": "XuMHtVpVcF-c",
        "outputId": "eba6d7fc-cb74-43a6-d52e-cc97abf1459a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "APIRemovedInV1",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-4a0842a8df05>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m response = openai.Completion.create(\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"davinci\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Social media post: \\\"That new Spider Man movie stinks to high heaven\\\"\\nSentiment (positive, neutral, negative):\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/lib/_old_api.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAPIRemovedInV1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_symbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1XJemgVcTzk",
        "outputId": "6c606106-19b6-47c6-ce12-8376b8409922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"length\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \" Negative\"\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1639577707,\n",
            "  \"id\": \"cmpl-4FPLfIQvBLsWX6ewmmTmkHarFKO8W\",\n",
            "  \"model\": \"davinci:2020-05-03\",\n",
            "  \"object\": \"text_completion\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci\",\n",
        "  prompt=\"Social media post: \\\"That new Spider Man movie is decent\\\"\\nSentiment (positive, neutral, negative):\",\n",
        "  temperature=0,\n",
        "  max_tokens=1,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEPHk552c2il",
        "outputId": "2ad4f425-201f-4a69-f8c4-91e6006bf82a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8kVgk1keM2I",
        "outputId": "fbd34e56-fbf4-4d88-8d3b-ee2813ad3088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"length\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \" positive\"\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1639577843,\n",
            "  \"id\": \"cmpl-4FPNrGBWvwFN76Eeyb5oIQHufsZ7J\",\n",
            "  \"model\": \"davinci:2020-05-03\",\n",
            "  \"object\": \"text_completion\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jd-lg20kyCZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci\",\n",
        "  prompt=\"Social media post: \\\"The first film had a much better balance between story and action. It seemed that this film had tons of unnecessary exposition (story really starts around 40 minutes into the movie), and the action was drawn out with lengthy CGI shots that did nothing to showcase the actors' talents, nothing to advance the story, and at provided little spectacle.\\\"\\nSentiment (positive, neutral, negative):\",\n",
        "  temperature=0,\n",
        "  max_tokens=1,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "Xef4oKEqmTUm",
        "outputId": "da74c9fa-7fde-46d1-80fd-cf7a07d7226a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "APIRemovedInV1",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-2fe6b0e492e8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m response = openai.Completion.create(\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"davinci\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Social media post: \\\"The first film had a much better balance between story and action. It seemed that this film had tons of unnecessary exposition (story really starts around 40 minutes into the movie), and the action was drawn out with lengthy CGI shots that did nothing to showcase the actors' talents, nothing to advance the story, and at provided little spectacle.\\\"\\nSentiment (positive, neutral, negative):\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/lib/_old_api.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAPIRemovedInV1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_symbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getSentiment(prompt, client=client, sentiments=(\"positive\",\"neutral\",\"negative\"), model=\"gpt-3.5-turbo\"):\n",
        "    sentiment_text = \",\".join(sentiments)  # I add all the sentiments in a string separated by comma\n",
        "    prompt=f\"Social media post: \\\"{prompt[:200]}\\\"Sentiment ({sentiment_text}):\"\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt,\n",
        "            }\n",
        "        ],\n",
        "        model=model,\n",
        "    )\n",
        "    return chat_completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "uqSeqhEcyFY-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "getSentiment(\"I really like bread and circuses\")"
      ],
      "metadata": {
        "id": "gwvz0Tbvyn2z",
        "outputId": "acc5895c-8d30-4270-aac5-55967269fbb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "getSentiment(\"Where do I begin? This is a brand new 4K scan from the original negative of the movie with an added HDR10 & Dolby Vision HDR grading, which looks fantastic!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yrZMnvmhnx1W",
        "outputId": "beaf0b2e-7e0f-4620-82a7-507eee8554c3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "getSentiment(\"Man patik alus\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Esn2RaidoN_n",
        "outputId": "8042e65f-874e-4bef-8020-b81b12f9be0e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "getSentiment(\"Man nepatƒ´k slidenas ielas\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0ZdW9uicoWXh",
        "outputId": "6e72c019-7411-4583-9903-135e41ecf579"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'negative'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "getSentiment(\"Man nepatƒ´k slidenas ielas\", sentiments=[\"pozitƒ´vs\", \"neitrƒÅls\", \"negatƒ´vs\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vj0lBNvfpDk4",
        "outputId": "c295f3a1-6947-485d-ba32-b1185f579ed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' neg'"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "getSentiment(\"Man patik alus\", sentiments=[\"pozitƒ´vs\", \"neitrƒÅls\", \"negatƒ´vs\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "I1uBEGwQpShR",
        "outputId": "b1c598c7-8c09-4d0b-d452-77f04a5d6e7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' po'"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getMovieEmoji(prompt):\n",
        "  response = openai.Completion.create(\n",
        "    engine=\"davinci\",\n",
        "    prompt=f\"Back to Future: üë®üë¥üöóüïí\\nBatman: ü§µü¶á\\nTransformers: üöóü§ñ\\nWonder Woman: üë∏üèªüë∏üèºüë∏üèΩüë∏üèæüë∏üèø\\nWinnie the Pooh: üêªüêºüêª\\nThe Godfather: üë®üë©üëßüïµüèª‚Äç‚ôÇÔ∏èüë≤üí•\\nGame of Thrones: üèπüó°üó°üèπ\\n{prompt}: \",\n",
        "    temperature=0.8,\n",
        "    max_tokens=60,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "    stop=[\"\\n\"]\n",
        "  )\n",
        "  return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "SWXEr_F9qbtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(getMovieEmoji(\"The Bourne Conspiracy\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XGO_WoNq6eM",
        "outputId": "aac781b6-0401-4c89-8ae1-f144e2ebdace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¬†üëÇüïµÔ∏èüî´üëÄ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.esrb.org/\n",
        "response = openai.Completion.create(\n",
        "  engine=\"davinci\",\n",
        "  prompt=\"Provide an ESRB rating for the following text:\\n\\n\\\"i'm going to blow your brains out with my ray gun then stomp on your guts.\\\"\\n\\nESRB rating:\",\n",
        "  temperature=0.7,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"\\n\"]\n",
        ")\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pIUj35jsAdM",
        "outputId": "696651f9-f070-46dd-f12a-df3b57a4ac70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject text_completion id=cmpl-4FQPw8iVbGBjszvuLLvn32LPRX51K at 0x7f23064ffe30> JSON: {\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"finish_reason\": \"stop\",\n",
              "      \"index\": 0,\n",
              "      \"logprobs\": null,\n",
              "      \"text\": \" M for Mature\"\n",
              "    }\n",
              "  ],\n",
              "  \"created\": 1639581816,\n",
              "  \"id\": \"cmpl-4FQPw8iVbGBjszvuLLvn32LPRX51K\",\n",
              "  \"model\": \"davinci:2020-05-03\",\n",
              "  \"object\": \"text_completion\"\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getESRB(prompt):\n",
        "  response = openai.Completion.create(\n",
        "  engine=\"davinci\",\n",
        "  prompt=f\"Provide an ESRB rating for the following text:\\n\\n\\\"{prompt}\\\"\\n\\nESRB rating:\",\n",
        "  temperature=0.7,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"\\n\"]\n",
        ")\n",
        "  return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "D78AYU8GsVEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "getESRB(\"It was a dark and stormy night\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FHJYunKNuUTd",
        "outputId": "3f5e95bf-9e4b-4bca-c05d-d755f2be5eed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' T for Teen for Violence, Blood and Gore, and Language'"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "getESRB(\"It was the best of times it was the worst of times\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GbR698W1ub-_",
        "outputId": "fcbe81e1-fad1-43ba-ffaa-b4c147c652b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' E10+'"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "getESRB(\"They say all happy families are alike but all unhappy families are different in their own way\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IaObBgequjrG",
        "outputId": "b1f877f5-277e-4577-b6bb-5d33ca02431e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' Teen'"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getStudyNotes(subject):\n",
        "  response = openai.Completion.create(\n",
        "  engine=\"davinci-instruct-beta\",\n",
        "  prompt=f\"What are some key points I should know when studying {subject}\\n\\n1.\",\n",
        "  temperature=1,\n",
        "  max_tokens=64,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0\n",
        ")\n",
        "  return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "Ti9Vdw62u2AY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "getStudyNotes(\"Riga\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7Aqk-WJTvZh5",
        "outputId": "077aad5e-9688-44cc-dc29-3ee956b7ec4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' a major port on a _____ stream flowing _____ Baltic sea _____.\\n\\n2. a _____ capital and _____ capital of _____ Latvia\\n\\n3. Copenhagen (Denmark)\\n\\n4. Famous for its Medieval architecture\\n\\n5. Riba (Russia)\\n\\nThe answers were'"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "notes = [getStudyNotes(\"Sentiment Analysis\") for _ in range(5)]  # i ran the same query 5 times, so text completion will be different each tie\n",
        "print(notes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKmTUYYcvkuR",
        "outputId": "0afb34d8-8cd1-4607-aea3-87e00b7e4afa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' Keywords and phrases can be negative even when they don‚Äôt seem to be\\n2. Popular sentiment analysis is not always the right analysis\\n3. Slang and capitals can make sentences seem negative', ' Semantria tracks sentiment globally by applying sentiment analysis models to content expressed in multiple languages.\\n2. Semantria sentiment analysis models come in three different methods which are Query Based, Feed Based, and Sentiment Match.\\n3. With Query Based sentiment analysis you can input a phrase or sentence for Semantria', \" Find out what is interesting about your business\\n2. Focus on your buying process\\n\\n3. Reduce capital inventory\\n4. Have the temperament of an artists\\n\\nWhat key points do you think I should know for this topic?\\n\\nYou shouldn't study how to do sentiment analysis or focus on this topic if\", ' Authors generally use sentiment words to convey approval versus a negative sentiment\\n a group holds about a person, company, issue, or life events.\\n2. Automated sentiment analysis is a technique for analyzing texts to make scientifically-based assessments on whether a text is of a broadly positive or negative tone\\n3. Classifiers', ' The sentiment of a sentence should take into account the sentiment of the words in it. So, for example, take the sentence ‚ÄúIt was great to get to study with you!‚Äù. By taking the sentiment of the words ‚Äústudy‚Äù, ‚Äúget‚Äù, and ‚Äúglad']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digital_discourse_notes = [getStudyNotes(\"Digital Discourse\") for _ in range(5)]\n",
        "for note in digital_discourse_notes:\n",
        "  print(note)\n",
        "  print(\"=\"*40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u11YHzV5wJ2f",
        "outputId": "314f598a-b022-49c9-a7b0-6d1c854cda8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " There is a relationship between the word used and the identity of the individual speaker.\n",
            "\n",
            "2. Gender can also change depending on the audience.\n",
            "\n",
            "3. Tone serves as a crucial component for comprehension.\n",
            "\n",
            "4. Slang and jargon differ from culture to culture and language to language\n",
            "\n",
            "5.\n",
            "========================================\n",
            "Doesn't exist in a bubble so we need to pay attention to the framing and the understanding and assumptions around the discourse\n",
            "\n",
            "2.It can be participatory and evolving\n",
            "\n",
            "3.We need to study the social and political dimensions\n",
            "\n",
            "4.Water cooler talk\n",
            "\n",
            "5. A means of both self\n",
            "========================================\n",
            " Digital Discourse includes the many locations of the discussion, such as a blog, a message board, a chatroom, a wiki, a MySpace page, a Facebook page, a YouTube video, etc.\n",
            "A) Different people have different digital practices when it comes to culture\n",
            "\n",
            "2. There are \"four\n",
            "========================================\n",
            " Textual and Visual 2. Readers and Writers 3. Poetic Knowledge and Poetic Practice 4. Technical and Cultural 5. Historical and Scientific 6. Analysis and Interdisciplinarity\n",
            "\n",
            "What is an example of a semantic textual bias in a document?\n",
            "\n",
            "A semantic textual bias in a document is it reads\n",
            "========================================\n",
            " The value of the status quo\n",
            "\n",
            "2. Stance\n",
            "\n",
            "3. The one who doesn't know\n",
            "\n",
            "4. Tools of language\n",
            "\n",
            "5. Summary\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getEssayOutline(subject):\n",
        "  response = openai.Completion.create(\n",
        "  engine=\"davinci\",\n",
        "  prompt=f\"Create an outline for an essay about {subject}:\\n\\nI: Introduction\",\n",
        "  temperature=0.7,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0\n",
        ")\n",
        "  return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "u08bJVfkw3e_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(getEssayOutline(\"Julius Cesar\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVrdpD2txQlc",
        "outputId": "9db87882-1893-4ba5-f0cf-5301cd9f8bb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "II: Julius Cesar\n",
            "\n",
            "III: Family background\n",
            "\n",
            "IIII: Early life\n",
            "\n",
            "IIII: Civil service\n",
            "\n",
            "V: Cesar and Crassus\n",
            "\n",
            "VI: Cesar and Pompey\n",
            "\n",
            "VII: Cesar and the provinces\n",
            "\n",
            "VIII:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(getEssayOutline(\"Tourism in Latvia\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMqJRBF9yCa9",
        "outputId": "55146e99-2f98-49e0-ab20-926a1fd6f3c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".\n",
            "\n",
            "- Tourism in Latvia.\n",
            "\n",
            "II: What are the main development directions of the tourism business in Latvia?\n",
            "\n",
            "- Growth of the tourism industry.\n",
            "\n",
            "- The tourism industry as one of the most dynamic economic sectors in Latvia.\n",
            "\n",
            "- Importance of the tourism industry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getHorrorStory(topic):\n",
        "  response = openai.Completion.create(\n",
        "  engine=\"davinci\",\n",
        "  prompt=f\"Topic: Breakfast\\nTwo-Sentence Horror Story: He always stops crying when I pour the milk on his cereal. I just have to remember not to let him see his face on the carton.\\n###\\nTopic: {topic}\\nTwo-Sentence Horror Story:\",\n",
        "  temperature=0.5,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.5,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"###\"]\n",
        ")\n",
        "  return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "wVXXn0Qdy8AI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(getHorrorStory(\"snow\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUv_ZK8AzLXE",
        "outputId": "ec242bf5-d10e-4f88-dc89-22d5909f3dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " I was walking home from work when I realized that I was the only one on the sidewalk. A few minutes later, I saw a snowplow coming down the road. I waved to get its attention, but it just kept on going.\n",
            "I don't know what happened to everyone else.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(getHorrorStory(\"Christmas\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCdaEt7XzYjI",
        "outputId": "25c8deba-7d0a-42d4-e1b1-286a57e4de58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The real Santa Claus was too fat to fit down the chimney, so he left a note saying he'd be back next year.\n",
            "Two-Sentence Horror Story: I think Santa Claus is going to kill me.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# once I have a list of some texts to analyzie\n",
        "# i can simply loop over them and clal my getSentiment function for each text/document\n",
        "my_tweets = [\"In October main exports partners were Lithuania, Estonia, Germany and United Kingdom. The main import partners were Lithuania, Russian Federation, Poland and Germany.\"\n",
        ",\"In October 2021 the foreign trade turnover of Latvia amounted to ‚Ç¨ 3.39 billion, which at current prices was 23.5% larger than a year ago.Exports value of goods was ‚¨ÜÔ∏è17.8% higher, but imports value of goods ‚¨ÜÔ∏è28.8% higher. \"]\n",
        "\n",
        "my_tweet_sentiments = [getSentiment(tweet) for tweet in my_tweets]\n",
        "my_tweet_sentiments"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaiMIPijzuzr",
        "outputId": "0aa4df47-0c80-41ac-c0bd-d9d237975230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' Positive', ' 0']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    }
  ]
}