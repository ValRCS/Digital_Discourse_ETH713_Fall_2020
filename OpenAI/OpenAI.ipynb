{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenAI.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "id": "KZnYIGn7bsV8",
        "outputId": "387b255c-43f5-4924-869b-9d7cd95f2861"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.11.4.tar.gz (152 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▏                             | 10 kB 18.3 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 20 kB 24.8 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 30 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 40 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 51 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 61 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 71 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 81 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 92 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 102 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 112 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 122 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 133 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 143 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 152 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from openai) (4.62.3)\n",
            "Collecting pandas>=1.2.3\n",
            "  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.3 MB 38.8 MB/s \n",
            "\u001b[?25hCollecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.2.0.39-py3-none-any.whl (161 kB)\n",
            "\u001b[K     |████████████████████████████████| 161 kB 44.2 MB/s \n",
            "\u001b[?25hCollecting openpyxl>=3.0.7\n",
            "  Downloading openpyxl-3.0.9-py2.py3-none-any.whl (242 kB)\n",
            "\u001b[K     |████████████████████████████████| 242 kB 59.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pandas-stubs>=1.1.0.11->openai) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.11.4-py3-none-any.whl size=161960 sha256=8e8e25c395e3e71dc4efca832be368a2ebded4969c4fcc0dada13c9ba08beb7d\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/60/b2/2275a37f6383cec638f9181c7289f2284ba574f8ddc7a836b8\n",
            "Successfully built openai\n",
            "Installing collected packages: pandas-stubs, pandas, openpyxl, openai\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Attempting uninstall: openpyxl\n",
            "    Found existing installation: openpyxl 2.5.9\n",
            "    Uninstalling openpyxl-2.5.9:\n",
            "      Successfully uninstalled openpyxl-2.5.9\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.3.5 which is incompatible.\u001b[0m\n",
            "Successfully installed openai-0.11.4 openpyxl-3.0.9 pandas-1.3.5 pandas-stubs-1.2.0.39\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "snFB8EfCbE8y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "openai.api_key = \"use_your_own_key!\"  #never share your private API keys with the world! read them from enviroment or private text file"
      ],
      "metadata": {
        "id": "DVAjoD-bb4Vf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci\",\n",
        "  prompt=\"Social media post: \\\"That new Spider Man movie stinks to high heaven\\\"\\nSentiment (positive, neutral, negative):\",\n",
        "  temperature=0,\n",
        "  max_tokens=1,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")"
      ],
      "metadata": {
        "id": "XuMHtVpVcF-c"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1XJemgVcTzk",
        "outputId": "6c606106-19b6-47c6-ce12-8376b8409922"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"length\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \" Negative\"\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1639577707,\n",
            "  \"id\": \"cmpl-4FPLfIQvBLsWX6ewmmTmkHarFKO8W\",\n",
            "  \"model\": \"davinci:2020-05-03\",\n",
            "  \"object\": \"text_completion\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci\",\n",
        "  prompt=\"Social media post: \\\"That new Spider Man movie is decent\\\"\\nSentiment (positive, neutral, negative):\",\n",
        "  temperature=0,\n",
        "  max_tokens=1,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEPHk552c2il",
        "outputId": "2ad4f425-201f-4a69-f8c4-91e6006bf82a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8kVgk1keM2I",
        "outputId": "fbd34e56-fbf4-4d88-8d3b-ee2813ad3088"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"length\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \" positive\"\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1639577843,\n",
            "  \"id\": \"cmpl-4FPNrGBWvwFN76Eeyb5oIQHufsZ7J\",\n",
            "  \"model\": \"davinci:2020-05-03\",\n",
            "  \"object\": \"text_completion\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  engine=\"davinci\",\n",
        "  prompt=\"Social media post: \\\"The first film had a much better balance between story and action. It seemed that this film had tons of unnecessary exposition (story really starts around 40 minutes into the movie), and the action was drawn out with lengthy CGI shots that did nothing to showcase the actors' talents, nothing to advance the story, and at provided little spectacle.\\\"\\nSentiment (positive, neutral, negative):\",\n",
        "  temperature=0,\n",
        "  max_tokens=1,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xef4oKEqmTUm",
        "outputId": "005445b1-ae3f-4998-9445-7e0491ddbe76"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getSentiment(prompt, sentiments=(\"positive\",\"neutral\",\"negative\")):\n",
        "  sentiment_text = \",\".join(sentiments)  # I add all the sentiments in a string separated by comma\n",
        "  response = openai.Completion.create(\n",
        "  engine=\"davinci\",\n",
        "  prompt=f\"Social media post: \\\"{prompt[:200]}\\\"Sentiment ({sentiment_text}):\",\n",
        "  temperature=0,\n",
        "  max_tokens=1,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "  return response[\"choices\"][0][\"text\"]  # some sentiments might not be classified as all positive or negative we might want to return more then"
      ],
      "metadata": {
        "id": "cwHMaKrrms77"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "getSentiment(\"I really like bread and circuses\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1MQSbfp4nMop",
        "outputId": "4cc24bf6-9daa-4509-f1ee-bae424d850ee"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' Positive'"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "getSentiment(\"Where do I begin? This is a brand new 4K scan from the original negative of the movie with an added HDR10 & Dolby Vision HDR grading, which looks fantastic!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yrZMnvmhnx1W",
        "outputId": "187f3cd5-ed37-4748-8fef-20c3d10a7b48"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' Positive'"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "getSentiment(\"Man patik alus\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Esn2RaidoN_n",
        "outputId": "dc7bdd00-3930-4c78-b21b-bda5401f3cd2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' Positive'"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "getSentiment(\"Man nepatīk slidenas ielas\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0ZdW9uicoWXh",
        "outputId": "d080dcff-4076-471c-c432-9d6052915d90"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' negative'"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "getSentiment(\"Man nepatīk slidenas ielas\", sentiments=[\"pozitīvs\", \"neitrāls\", \"negatīvs\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vj0lBNvfpDk4",
        "outputId": "c295f3a1-6947-485d-ba32-b1185f579ed3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' neg'"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "getSentiment(\"Man patik alus\", sentiments=[\"pozitīvs\", \"neitrāls\", \"negatīvs\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "I1uBEGwQpShR",
        "outputId": "b1c598c7-8c09-4d0b-d452-77f04a5d6e7a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' po'"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getMovieEmoji(prompt):\n",
        "  response = openai.Completion.create(\n",
        "    engine=\"davinci\",\n",
        "    prompt=f\"Back to Future: 👨👴🚗🕒\\nBatman: 🤵🦇\\nTransformers: 🚗🤖\\nWonder Woman: 👸🏻👸🏼👸🏽👸🏾👸🏿\\nWinnie the Pooh: 🐻🐼🐻\\nThe Godfather: 👨👩👧🕵🏻‍♂️👲💥\\nGame of Thrones: 🏹🗡🗡🏹\\n{prompt}: \",\n",
        "    temperature=0.8,\n",
        "    max_tokens=60,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "    stop=[\"\\n\"]\n",
        "  )\n",
        "  return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "SWXEr_F9qbtH"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(getMovieEmoji(\"The Bourne Conspiracy\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XGO_WoNq6eM",
        "outputId": "aac781b6-0401-4c89-8ae1-f144e2ebdace"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 👂🕵️🔫👀\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.esrb.org/\n",
        "response = openai.Completion.create(\n",
        "  engine=\"davinci\",\n",
        "  prompt=\"Provide an ESRB rating for the following text:\\n\\n\\\"i'm going to blow your brains out with my ray gun then stomp on your guts.\\\"\\n\\nESRB rating:\",\n",
        "  temperature=0.7,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"\\n\"]\n",
        ")\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pIUj35jsAdM",
        "outputId": "696651f9-f070-46dd-f12a-df3b57a4ac70"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject text_completion id=cmpl-4FQPw8iVbGBjszvuLLvn32LPRX51K at 0x7f23064ffe30> JSON: {\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"finish_reason\": \"stop\",\n",
              "      \"index\": 0,\n",
              "      \"logprobs\": null,\n",
              "      \"text\": \" M for Mature\"\n",
              "    }\n",
              "  ],\n",
              "  \"created\": 1639581816,\n",
              "  \"id\": \"cmpl-4FQPw8iVbGBjszvuLLvn32LPRX51K\",\n",
              "  \"model\": \"davinci:2020-05-03\",\n",
              "  \"object\": \"text_completion\"\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getESRB(prompt):\n",
        "  response = openai.Completion.create(\n",
        "  engine=\"davinci\",\n",
        "  prompt=f\"Provide an ESRB rating for the following text:\\n\\n\\\"{prompt}\\\"\\n\\nESRB rating:\",\n",
        "  temperature=0.7,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"\\n\"]\n",
        ")\n",
        "  return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "D78AYU8GsVEd"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "getESRB(\"It was a dark and stormy night\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FHJYunKNuUTd",
        "outputId": "3f5e95bf-9e4b-4bca-c05d-d755f2be5eed"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' T for Teen for Violence, Blood and Gore, and Language'"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "getESRB(\"It was the best of times it was the worst of times\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GbR698W1ub-_",
        "outputId": "fcbe81e1-fad1-43ba-ffaa-b4c147c652b4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' E10+'"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "getESRB(\"They say all happy families are alike but all unhappy families are different in their own way\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IaObBgequjrG",
        "outputId": "b1f877f5-277e-4577-b6bb-5d33ca02431e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' Teen'"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getStudyNotes(subject):\n",
        "  response = openai.Completion.create(\n",
        "  engine=\"davinci-instruct-beta\",\n",
        "  prompt=f\"What are some key points I should know when studying {subject}\\n\\n1.\",\n",
        "  temperature=1,\n",
        "  max_tokens=64,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0\n",
        ")\n",
        "  return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "Ti9Vdw62u2AY"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "getStudyNotes(\"Riga\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7Aqk-WJTvZh5",
        "outputId": "077aad5e-9688-44cc-dc29-3ee956b7ec4b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' a major port on a _____ stream flowing _____ Baltic sea _____.\\n\\n2. a _____ capital and _____ capital of _____ Latvia\\n\\n3. Copenhagen (Denmark)\\n\\n4. Famous for its Medieval architecture\\n\\n5. Riba (Russia)\\n\\nThe answers were'"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "notes = [getStudyNotes(\"Sentiment Analysis\") for _ in range(5)]  # i ran the same query 5 times, so text completion will be different each tie\n",
        "print(notes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKmTUYYcvkuR",
        "outputId": "0afb34d8-8cd1-4607-aea3-87e00b7e4afa"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' Keywords and phrases can be negative even when they don’t seem to be\\n2. Popular sentiment analysis is not always the right analysis\\n3. Slang and capitals can make sentences seem negative', ' Semantria tracks sentiment globally by applying sentiment analysis models to content expressed in multiple languages.\\n2. Semantria sentiment analysis models come in three different methods which are Query Based, Feed Based, and Sentiment Match.\\n3. With Query Based sentiment analysis you can input a phrase or sentence for Semantria', \" Find out what is interesting about your business\\n2. Focus on your buying process\\n\\n3. Reduce capital inventory\\n4. Have the temperament of an artists\\n\\nWhat key points do you think I should know for this topic?\\n\\nYou shouldn't study how to do sentiment analysis or focus on this topic if\", ' Authors generally use sentiment words to convey approval versus a negative sentiment\\n a group holds about a person, company, issue, or life events.\\n2. Automated sentiment analysis is a technique for analyzing texts to make scientifically-based assessments on whether a text is of a broadly positive or negative tone\\n3. Classifiers', ' The sentiment of a sentence should take into account the sentiment of the words in it. So, for example, take the sentence “It was great to get to study with you!”. By taking the sentiment of the words “study”, “get”, and “glad']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digital_discourse_notes = [getStudyNotes(\"Digital Discourse\") for _ in range(5)]\n",
        "for note in digital_discourse_notes:\n",
        "  print(note)\n",
        "  print(\"=\"*40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u11YHzV5wJ2f",
        "outputId": "314f598a-b022-49c9-a7b0-6d1c854cda8c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " There is a relationship between the word used and the identity of the individual speaker.\n",
            "\n",
            "2. Gender can also change depending on the audience.\n",
            "\n",
            "3. Tone serves as a crucial component for comprehension.\n",
            "\n",
            "4. Slang and jargon differ from culture to culture and language to language\n",
            "\n",
            "5.\n",
            "========================================\n",
            "Doesn't exist in a bubble so we need to pay attention to the framing and the understanding and assumptions around the discourse\n",
            "\n",
            "2.It can be participatory and evolving\n",
            "\n",
            "3.We need to study the social and political dimensions\n",
            "\n",
            "4.Water cooler talk\n",
            "\n",
            "5. A means of both self\n",
            "========================================\n",
            " Digital Discourse includes the many locations of the discussion, such as a blog, a message board, a chatroom, a wiki, a MySpace page, a Facebook page, a YouTube video, etc.\n",
            "A) Different people have different digital practices when it comes to culture\n",
            "\n",
            "2. There are \"four\n",
            "========================================\n",
            " Textual and Visual 2. Readers and Writers 3. Poetic Knowledge and Poetic Practice 4. Technical and Cultural 5. Historical and Scientific 6. Analysis and Interdisciplinarity\n",
            "\n",
            "What is an example of a semantic textual bias in a document?\n",
            "\n",
            "A semantic textual bias in a document is it reads\n",
            "========================================\n",
            " The value of the status quo\n",
            "\n",
            "2. Stance\n",
            "\n",
            "3. The one who doesn't know\n",
            "\n",
            "4. Tools of language\n",
            "\n",
            "5. Summary\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getEssayOutline(subject):\n",
        "  response = openai.Completion.create(\n",
        "  engine=\"davinci\",\n",
        "  prompt=f\"Create an outline for an essay about {subject}:\\n\\nI: Introduction\",\n",
        "  temperature=0.7,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0\n",
        ")\n",
        "  return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "u08bJVfkw3e_"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(getEssayOutline(\"Julius Cesar\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVrdpD2txQlc",
        "outputId": "9db87882-1893-4ba5-f0cf-5301cd9f8bb3"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "II: Julius Cesar\n",
            "\n",
            "III: Family background\n",
            "\n",
            "IIII: Early life\n",
            "\n",
            "IIII: Civil service\n",
            "\n",
            "V: Cesar and Crassus\n",
            "\n",
            "VI: Cesar and Pompey\n",
            "\n",
            "VII: Cesar and the provinces\n",
            "\n",
            "VIII:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(getEssayOutline(\"Tourism in Latvia\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMqJRBF9yCa9",
        "outputId": "55146e99-2f98-49e0-ab20-926a1fd6f3c3"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".\n",
            "\n",
            "- Tourism in Latvia.\n",
            "\n",
            "II: What are the main development directions of the tourism business in Latvia?\n",
            "\n",
            "- Growth of the tourism industry.\n",
            "\n",
            "- The tourism industry as one of the most dynamic economic sectors in Latvia.\n",
            "\n",
            "- Importance of the tourism industry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getHorrorStory(topic):\n",
        "  response = openai.Completion.create(\n",
        "  engine=\"davinci\",\n",
        "  prompt=f\"Topic: Breakfast\\nTwo-Sentence Horror Story: He always stops crying when I pour the milk on his cereal. I just have to remember not to let him see his face on the carton.\\n###\\nTopic: {topic}\\nTwo-Sentence Horror Story:\",\n",
        "  temperature=0.5,\n",
        "  max_tokens=60,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.5,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"###\"]\n",
        ")\n",
        "  return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "wVXXn0Qdy8AI"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(getHorrorStory(\"snow\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUv_ZK8AzLXE",
        "outputId": "ec242bf5-d10e-4f88-dc89-22d5909f3dd2"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " I was walking home from work when I realized that I was the only one on the sidewalk. A few minutes later, I saw a snowplow coming down the road. I waved to get its attention, but it just kept on going.\n",
            "I don't know what happened to everyone else.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(getHorrorStory(\"Christmas\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCdaEt7XzYjI",
        "outputId": "25c8deba-7d0a-42d4-e1b1-286a57e4de58"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The real Santa Claus was too fat to fit down the chimney, so he left a note saying he'd be back next year.\n",
            "Two-Sentence Horror Story: I think Santa Claus is going to kill me.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# once I have a list of some texts to analyzie\n",
        "# i can simply loop over them and clal my getSentiment function for each text/document\n",
        "my_tweets = [\"In October main exports partners were Lithuania, Estonia, Germany and United Kingdom. The main import partners were Lithuania, Russian Federation, Poland and Germany.\"\n",
        ",\"In October 2021 the foreign trade turnover of Latvia amounted to € 3.39 billion, which at current prices was 23.5% larger than a year ago.Exports value of goods was ⬆️17.8% higher, but imports value of goods ⬆️28.8% higher. \"]\n",
        "\n",
        "my_tweet_sentiments = [getSentiment(tweet) for tweet in my_tweets]\n",
        "my_tweet_sentiments"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaiMIPijzuzr",
        "outputId": "0aa4df47-0c80-41ac-c0bd-d9d237975230"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' Positive', ' 0']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    }
  ]
}